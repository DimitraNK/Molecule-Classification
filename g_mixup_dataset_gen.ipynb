{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installations"
      ],
      "metadata": {
        "id": "BW35vfeXqyCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q24-PWI8Iwd7",
        "outputId": "8da01425-c5a6-4865-f585-ff13344c8284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ogb"
      ],
      "metadata": {
        "id": "BecbS35f92_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "212b7709-ddc9-4793-f6f3-e8e7ed4cdf29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ogb\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (4.65.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.26.16)\n",
            "Collecting outdated>=0.2.0 (from ogb)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb)\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (2.27.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2022.7.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->ogb) (2.1.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7029 sha256=d877d37ac9486f3687c00bff5b2b3a3e4f047dcd50eec767bb7dbdb2a7b7cfea\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, outdated, ogb\n",
            "Successfully installed littleutils-0.2.2 ogb-1.3.6 outdated-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "id": "e_Oz2Vxi-V4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db2399b0-3b87-49cc-98eb-af9eac8c61e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.27.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910459 sha256=532e10b9d8787e2b10351c5153d43f4c6ce429aed56ebae48448e3c7d0f47bc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DAiUWZ5NK7C",
        "outputId": "aca1199f-6618-42af-a464-b2c835094759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rdkit\n",
            "  Using cached rdkit-2023.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n",
            "Collecting Pillow\n",
            "  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from rdkit) (1.25.0)\n",
            "Installing collected packages: Pillow, rdkit\n",
            "Successfully installed Pillow-9.5.0 rdkit-2023.3.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aToKo-xHoeX7",
        "outputId": "7f024caa-790e-4b09-d29d-77d9fb8d6f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m✨🍰✨ Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install -c conda-forge torch-scatter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDLyc4cMx2ll",
        "outputId": "803ab54a-491d-480b-b7c1-e4f5b0d9cde0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 23.3.1\n",
            "  latest version: 23.5.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "Or to minimize the number of packages updated during conda update use\n",
            "\n",
            "     conda install conda=23.5.0\n",
            "\n",
            "\n",
            "\n",
            "# All requested packages already installed.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eEiH55n6pMoz",
        "outputId": "025e47af-b934-4efd-a487-805f27109bab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   HIV_active                                             smiles\n",
              "0           0  CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...\n",
              "1           0  C(=Cc1ccccc1)C1=[O+][Cu-3]2([O+]=C(C=Cc3ccccc3...\n",
              "2           0                   CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21\n",
              "3           0    Nc1ccc(C=Cc2ccc(N)cc2S(=O)(=O)O)c(S(=O)(=O)O)c1\n",
              "4           0                             O=S(=O)(O)CCS(=O)(=O)O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0bd6b29b-be47-4d9d-a587-12713a03b103\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HIV_active</th>\n",
              "      <th>smiles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>C(=Cc1ccccc1)C1=[O+][Cu-3]2([O+]=C(C=Cc3ccccc3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Nc1ccc(C=Cc2ccc(N)cc2S(=O)(=O)O)c(S(=O)(=O)O)c1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>O=S(=O)(O)CCS(=O)(=O)O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bd6b29b-be47-4d9d-a587-12713a03b103')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0bd6b29b-be47-4d9d-a587-12713a03b103 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0bd6b29b-be47-4d9d-a587-12713a03b103');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import torch\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "from ogb.graphproppred import PygGraphPropPredDataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load the ogbg-molhiv dataset\n",
        "csv_path = '/content/drive/My Drive/Colab Notebooks/Molecule Classification/hiv.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "df.head(5)\n",
        "df.drop('mol_id', axis='columns', inplace=True)\n",
        "df.head(5)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert the SMILES strings to graphs"
      ],
      "metadata": {
        "id": "q7r3xpcR09cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ogb.utils.features import (allowable_features, atom_to_feature_vector,\n",
        " bond_to_feature_vector, atom_feature_vector_to_dict, bond_feature_vector_to_dict)\n",
        "from rdkit import Chem\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def ReorderCanonicalRankAtoms(mol):\n",
        "    order = tuple(zip(*sorted([(j, i) for i, j in enumerate(Chem.CanonicalRankAtoms(mol))])))[1]\n",
        "    mol_renum = Chem.RenumberAtoms(mol, order)\n",
        "    return mol_renum, order\n",
        "\n",
        "def smiles2graph(smiles_string, removeHs=True, reorder_atoms=False):\n",
        "    \"\"\"\n",
        "    Converts SMILES string to graph Data object\n",
        "    :input: SMILES string (str)\n",
        "    :return: graph object\n",
        "    \"\"\"\n",
        "\n",
        "    mol = Chem.MolFromSmiles(smiles_string)\n",
        "    mol = mol if removeHs else Chem.AddHs(mol)\n",
        "    if reorder_atoms:\n",
        "        mol, _ = ReorderCanonicalRankAtoms(mol)\n",
        "\n",
        "    # atoms\n",
        "    atom_features_list = []\n",
        "    for atom in mol.GetAtoms():\n",
        "        atom_features_list.append(atom_to_feature_vector(atom))\n",
        "    x = np.array(atom_features_list, dtype = np.int64)\n",
        "\n",
        "    # bonds\n",
        "    num_bond_features = 3  # bond type, bond stereo, is_conjugated\n",
        "    if len(mol.GetBonds()) > 0: # mol has bonds\n",
        "        edges_list = []\n",
        "        edge_features_list = []\n",
        "        for bond in mol.GetBonds():\n",
        "            i = bond.GetBeginAtomIdx()\n",
        "            j = bond.GetEndAtomIdx()\n",
        "\n",
        "            edge_feature = bond_to_feature_vector(bond)\n",
        "\n",
        "            # add edges in both directions\n",
        "            edges_list.append((i, j))\n",
        "            edge_features_list.append(edge_feature)\n",
        "            edges_list.append((j, i))\n",
        "            edge_features_list.append(edge_feature)\n",
        "\n",
        "        # data.edge_index: Graph connectivity in COO format with shape [2, num_edges]\n",
        "        edge_index = np.array(edges_list, dtype = np.int64).T\n",
        "\n",
        "        # data.edge_attr: Edge feature matrix with shape [num_edges, num_edge_features]\n",
        "        edge_attr = np.array(edge_features_list, dtype = np.int64)\n",
        "\n",
        "    else:   # mol has no bonds\n",
        "        edge_index = np.empty((2, 0), dtype = np.int64)\n",
        "        edge_attr = np.empty((0, num_bond_features), dtype = np.int64)\n",
        "\n",
        "    graph = dict()\n",
        "    graph['edge_index'] = edge_index\n",
        "    graph['edge_feat'] = edge_attr\n",
        "    graph['node_feat'] = x\n",
        "    graph['num_nodes'] = len(x)\n",
        "\n",
        "    return graph\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    #graph = smiles2graph('O1C=C[C@H]([C@H]1O2)c3c2cc(OC)c4c3OC(=O)C5=C4CCC(=O)5')\n",
        "    #print(graph)\n",
        "    #print(type(graph))\n",
        "    targets = df['HIV_active']\n",
        "    data_list = [smiles2graph(mol) for mol in df['smiles']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVLZRJEM089b",
        "outputId": "e399ab11-4d4a-4756-f217-afe18c2ebac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[12:18:29] WARNING: not removing hydrogen atom without neighbors\n",
            "[12:18:29] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = pd.DataFrame(data_list)\n",
        "final_data = pd.concat([data_df,targets],axis=1)\n",
        "print(final_data.head(5))\n",
        "print(len(final_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ePJThz5QqVJ",
        "outputId": "5ff47f90-2301-48c6-b250-6de3df3f65ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          edge_index  \\\n",
            "0  [[0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7,...   \n",
            "1  [[0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 0,...   \n",
            "2  [[0, 1, 1, 2, 1, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7,...   \n",
            "3  [[0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7,...   \n",
            "4  [[0, 1, 1, 2, 1, 3, 1, 4, 4, 5, 5, 6, 6, 7, 6,...   \n",
            "\n",
            "                                           edge_feat  \\\n",
            "0  [[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [...   \n",
            "1  [[1, 0, 1], [1, 0, 1], [0, 0, 1], [0, 0, 1], [...   \n",
            "2  [[0, 0, 0], [0, 0, 0], [1, 0, 1], [1, 0, 1], [...   \n",
            "3  [[0, 0, 1], [0, 0, 1], [3, 0, 1], [3, 0, 1], [...   \n",
            "4  [[1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [...   \n",
            "\n",
            "                                           node_feat  num_nodes  HIV_active  \n",
            "0  [[5, 0, 4, 5, 3, 0, 2, 0, 0], [5, 0, 4, 5, 2, ...         19           0  \n",
            "1  [[5, 0, 3, 5, 1, 0, 1, 0, 0], [5, 0, 3, 5, 1, ...         39           0  \n",
            "2  [[5, 0, 4, 5, 3, 0, 2, 0, 0], [5, 0, 3, 5, 0, ...         21           0  \n",
            "3  [[6, 0, 3, 5, 2, 0, 1, 0, 0], [5, 0, 3, 5, 0, ...         24           0  \n",
            "4  [[7, 0, 1, 5, 0, 0, 1, 0, 0], [15, 0, 4, 5, 0,...         10           0  \n",
            "41127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_list[0])\n",
        "print(len(data_list))\n",
        "print(len(targets))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC-vF71f2qsy",
        "outputId": "56a95445-eaaa-4b43-d0ae-22e6bdc9a2e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'edge_index': array([[ 0,  1,  1,  2,  2,  3,  3,  4,  4,  5,  5,  6,  6,  7,  7,  8,\n",
            "         6,  9,  4, 10, 10, 11, 11, 12, 12, 13, 11, 14, 14, 15, 15, 16,\n",
            "        16, 17, 15, 18,  9,  2, 18,  4],\n",
            "       [ 1,  0,  2,  1,  3,  2,  4,  3,  5,  4,  6,  5,  7,  6,  8,  7,\n",
            "         9,  6, 10,  4, 11, 10, 12, 11, 13, 12, 14, 11, 15, 14, 16, 15,\n",
            "        17, 16, 18, 15,  2,  9,  4, 18]]), 'edge_feat': array([[0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [1, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0],\n",
            "       [0, 0, 0]]), 'node_feat': array([[ 5,  0,  4,  5,  3,  0,  2,  0,  0],\n",
            "       [ 5,  0,  4,  5,  2,  0,  2,  0,  0],\n",
            "       [ 5,  0,  3,  5,  0,  0,  1,  0,  1],\n",
            "       [ 7,  0,  2,  6,  0,  0,  1,  0,  1],\n",
            "       [28,  0,  4,  2,  0,  0,  5,  0,  1],\n",
            "       [ 7,  0,  2,  6,  0,  0,  1,  0,  1],\n",
            "       [ 5,  0,  3,  5,  0,  0,  1,  0,  1],\n",
            "       [ 5,  0,  4,  5,  2,  0,  2,  0,  0],\n",
            "       [ 5,  0,  4,  5,  3,  0,  2,  0,  0],\n",
            "       [ 5,  0,  4,  5,  2,  0,  2,  0,  1],\n",
            "       [ 7,  0,  2,  6,  0,  0,  1,  0,  1],\n",
            "       [ 5,  0,  3,  5,  0,  0,  1,  0,  1],\n",
            "       [ 5,  0,  4,  5,  2,  0,  2,  0,  0],\n",
            "       [ 5,  0,  4,  5,  3,  0,  2,  0,  0],\n",
            "       [ 5,  0,  4,  5,  2,  0,  2,  0,  1],\n",
            "       [ 5,  0,  3,  5,  0,  0,  1,  0,  1],\n",
            "       [ 5,  0,  4,  5,  2,  0,  2,  0,  0],\n",
            "       [ 5,  0,  4,  5,  3,  0,  2,  0,  0],\n",
            "       [ 7,  0,  2,  6,  0,  0,  1,  0,  1]]), 'num_nodes': 19}\n",
            "41127\n",
            "41127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Dataset Class\n",
        "We create a custom dataset class to ensure that our dataset is in the correct format for the g-mixup functions we implemented."
      ],
      "metadata": {
        "id": "RvnjXEZ5uS8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Dataset, Data\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None, pre_transform=None):\n",
        "        super(CustomDataset, self).__init__(transform, pre_transform)\n",
        "\n",
        "        # Store your custom dataframe\n",
        "        self.dataframe = dataframe\n",
        "\n",
        "        # Perform any necessary preprocessing steps on your dataframe here\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def get(self, idx):\n",
        "        # Retrieve the graph data for the given index from your dataframe\n",
        "        # and convert it to the required format for torch_geometric.Data\n",
        "\n",
        "        # Extract relevant information from the dataframe\n",
        "        graph_data = self.dataframe.iloc[idx]\n",
        "        # Process the graph data and create a torch_geometric.Data object\n",
        "        x = torch.tensor(graph_data['node_feat'], dtype=torch.float)\n",
        "        y = torch.tensor(graph_data['HIV_active'], dtype=torch.long)\n",
        "        edge_index = torch.tensor(graph_data['edge_index'], dtype=torch.long).t().contiguous()\n",
        "        edge_attr = torch.tensor(graph_data['edge_feat'], dtype=torch.float)\n",
        "        num_nodes = torch.tensor(graph_data['num_nodes'], dtype=torch.float)\n",
        "\n",
        "        data = Data(x=x, y=y, edge_index=edge_index, edge_attr=edge_attr,num_nodes=num_nodes)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            data = self.transform(data)\n",
        "\n",
        "        return data"
      ],
      "metadata": {
        "id": "XzGvIh_oQn71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_dataset = CustomDataset(dataframe=final_data)\n",
        "print(custom_dataset[2])\n",
        "print(custom_dataset.len())\n",
        "print(custom_dataset.get(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMoAbPAOTYg9",
        "outputId": "423fcdc0-c5ae-47d5-93f6-99e5806fd353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[21, 9], edge_index=[48, 2], edge_attr=[48, 3], y=0, num_nodes=21.0)\n",
            "41127\n",
            "Data(x=[39, 9], edge_index=[88, 2], edge_attr=[88, 3], y=0, num_nodes=39.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *G* - Mixup\n",
        "We implemented g-mixup functions, so that they would work for our intended purpose and our dataset. Although the following code is inspired by the idea proposed in the *G* - Mixup paper (https://arxiv.org/abs/2202.07179), it is not the same code.\n",
        "The code from the *G* - Mixup paper can be found in this GitHub repository: https://github.com/ahxt/g-mixup."
      ],
      "metadata": {
        "id": "EblQLlGGukPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#g-mixup\n",
        "import torch\n",
        "from typing import List, Tuple\n",
        "from torch_geometric.data import Data\n",
        "import random\n",
        "from torch_geometric.utils import degree , dense_to_sparse\n",
        "import logging\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "from torch_geometric.datasets import TUDataset\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.DEBUG)\n",
        "formatter = logging.Formatter('%(asctime)s - %(levelname)s: - %(message)s', datefmt='%Y-%m-%d')\n",
        "\n",
        "def prepare_dataset_onehot_y(dataset):\n",
        "\n",
        "    y_set = set()\n",
        "    for data in dataset:\n",
        "        y_set.add(int(data.y))\n",
        "    num_classes = len(y_set)\n",
        "\n",
        "    for data in dataset:\n",
        "        data.y = F.one_hot(data.y, num_classes=num_classes).to(torch.float)[0]\n",
        "    return dataset\n",
        "\n",
        "def stat_graph(graphs_list: List[Data]):\n",
        "    num_total_nodes = []\n",
        "    num_total_edges = []\n",
        "    for graph in graphs_list:\n",
        "        num_total_nodes.append(graph.num_nodes)\n",
        "        num_total_edges.append(  graph.edge_index.shape[1] )\n",
        "    avg_num_nodes = sum( num_total_nodes ) / len(graphs_list)\n",
        "    avg_num_edges = sum( num_total_edges ) / len(graphs_list) / 2.0\n",
        "    avg_density = avg_num_edges / (avg_num_nodes * avg_num_nodes)\n",
        "\n",
        "    median_num_nodes = np.median( num_total_nodes )\n",
        "    median_num_edges = np.median(num_total_edges)\n",
        "    median_density = median_num_edges / (median_num_nodes * median_num_nodes)\n",
        "\n",
        "    return avg_num_nodes, avg_num_edges, avg_density, median_num_nodes, median_num_edges, median_density\n",
        "\n",
        "def split_class_graphs(dataset):\n",
        "\n",
        "    y_list = []\n",
        "    for data in dataset:\n",
        "        y_list.append(tuple(data.y.tolist()))\n",
        "        # print(y_list)\n",
        "    num_classes = len(set(y_list))\n",
        "\n",
        "    all_graphs_list = []\n",
        "    for graph in dataset:\n",
        "        adj = to_dense_adj(graph.edge_index)[0].numpy()\n",
        "        all_graphs_list.append(adj)\n",
        "\n",
        "    class_graphs = []\n",
        "    for class_label in set(y_list):\n",
        "        c_graph_list = [all_graphs_list[i] for i in range(len(y_list)) if y_list[i] == class_label]\n",
        "        class_graphs.append( ( np.array(class_label), c_graph_list ) )\n",
        "\n",
        "    return class_graphs\n",
        "\n",
        "def align_graphs(graphs: List[np.ndarray],\n",
        "                 padding: bool = False, N: int = None) -> Tuple[List[np.ndarray], List[np.ndarray], int, int]:\n",
        "    \"\"\"\n",
        "    Align multiple graphs by sorting their nodes by descending node degrees\n",
        "    :param graphs: a list of binary adjacency matrices\n",
        "    :param padding: whether padding graphs to the same size or not\n",
        "    :return:\n",
        "        aligned_graphs: a list of aligned adjacency matrices\n",
        "        normalized_node_degrees: a list of sorted normalized node degrees (as node distributions)\n",
        "    \"\"\"\n",
        "    num_nodes = [graphs[i].shape[0] for i in range(len(graphs))]\n",
        "    max_num = max(num_nodes)\n",
        "    min_num = min(num_nodes)\n",
        "\n",
        "    aligned_graphs = []\n",
        "    normalized_node_degrees = []\n",
        "    for i in range(len(graphs)):\n",
        "        num_i = graphs[i].shape[0]\n",
        "\n",
        "        node_degree = 0.5 * np.sum(graphs[i], axis=0) + 0.5 * np.sum(graphs[i], axis=1)\n",
        "        node_degree /= np.sum(node_degree)\n",
        "        idx = np.argsort(node_degree)  # ascending\n",
        "        idx = idx[::-1]  # descending\n",
        "\n",
        "        sorted_node_degree = node_degree[idx]\n",
        "        sorted_node_degree = sorted_node_degree.reshape(-1, 1)\n",
        "\n",
        "        sorted_graph = copy.deepcopy(graphs[i])\n",
        "        sorted_graph = sorted_graph[idx, :]\n",
        "        sorted_graph = sorted_graph[:, idx]\n",
        "\n",
        "        max_num = max(max_num, N)\n",
        "\n",
        "        if padding:\n",
        "            # normalized_node_degree = np.ones((max_num, 1)) / max_num\n",
        "            normalized_node_degree = np.zeros((max_num, 1))\n",
        "            normalized_node_degree[:num_i, :] = sorted_node_degree\n",
        "\n",
        "            aligned_graph = np.zeros((max_num, max_num))\n",
        "            aligned_graph[:num_i, :num_i] = sorted_graph\n",
        "\n",
        "            normalized_node_degrees.append(normalized_node_degree)\n",
        "            aligned_graphs.append(aligned_graph)\n",
        "        else:\n",
        "            normalized_node_degrees.append(sorted_node_degree)\n",
        "            aligned_graphs.append(sorted_graph)\n",
        "\n",
        "        if N:\n",
        "            aligned_graphs = [aligned_graph[:N, :N] for aligned_graph in aligned_graphs]\n",
        "            normalized_node_degrees = normalized_node_degrees[:N]\n",
        "\n",
        "    return aligned_graphs, normalized_node_degrees, max_num, min_num\n",
        "\n",
        "def graph_numpy2tensor(graphs: List[np.ndarray]) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Convert a list of np arrays to a pytorch tensor\n",
        "    :param graphs: [K (N, N) adjacency matrices]\n",
        "    :return:\n",
        "        graph_tensor: [K, N, N] tensor\n",
        "    \"\"\"\n",
        "    graph_tensor = np.array(graphs)\n",
        "    return torch.from_numpy(graph_tensor).float()\n",
        "\n",
        "def universal_svd(aligned_graphs: List[np.ndarray], threshold: float = 2.02) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Estimate a graphon by universal singular value thresholding.\n",
        "    Reference:\n",
        "    Chatterjee, Sourav.\n",
        "    \"Matrix estimation by universal singular value thresholding.\"\n",
        "    The Annals of Statistics 43.1 (2015): 177-214.\n",
        "    :param aligned_graphs: a list of (N, N) adjacency matrices\n",
        "    :param threshold: the threshold for singular values\n",
        "    :return: graphon: the estimated (r, r) graphon model\n",
        "    \"\"\"\n",
        "    aligned_graphs = graph_numpy2tensor(aligned_graphs)\n",
        "    num_graphs = aligned_graphs.size(0)\n",
        "\n",
        "    if num_graphs > 1:\n",
        "        sum_graph = torch.mean(aligned_graphs, dim=0)\n",
        "    else:\n",
        "        sum_graph = aligned_graphs[0, :, :]  # (N, N)\n",
        "\n",
        "    num_nodes = sum_graph.size(0)\n",
        "\n",
        "    u, s, v = torch.svd(sum_graph)\n",
        "    singular_threshold = threshold * (num_nodes ** 0.5)\n",
        "    binary_s = torch.lt(s, singular_threshold)\n",
        "    s[binary_s] = 0\n",
        "    graphon = u @ torch.diag(s) @ torch.t(v)\n",
        "    graphon[graphon > 1] = 1\n",
        "    graphon[graphon < 0] = 0\n",
        "    graphon = graphon.numpy()\n",
        "    return graphon\n",
        "\n",
        "def two_graphons_mixup(two_graphons, la=0.5, num_sample=20):\n",
        "\n",
        "    label = la * two_graphons[0][0] + (1 - la) * two_graphons[1][0]\n",
        "    new_graphon = la * two_graphons[0][1] + (1 - la) * two_graphons[1][1]\n",
        "\n",
        "    sample_graph_label = torch.from_numpy(label).type(torch.float32)\n",
        "    # print(new_graphon)\n",
        "\n",
        "    sample_graphs = []\n",
        "    for i in range(num_sample):\n",
        "\n",
        "        sample_graph = (np.random.rand(*new_graphon.shape) <= new_graphon).astype(np.int32)\n",
        "        sample_graph = np.triu(sample_graph)\n",
        "        sample_graph = sample_graph + sample_graph.T - np.diag(np.diag(sample_graph))\n",
        "\n",
        "        sample_graph = sample_graph[sample_graph.sum(axis=1) != 0]\n",
        "        sample_graph = sample_graph[:, sample_graph.sum(axis=0) != 0]\n",
        "\n",
        "        A = torch.from_numpy(sample_graph)\n",
        "        edge_index, _ = dense_to_sparse(A)\n",
        "\n",
        "        num_nodes = int(torch.max(edge_index)) + 1\n",
        "\n",
        "        pyg_graph = Data()\n",
        "        pyg_graph.y = sample_graph_label\n",
        "        pyg_graph.edge_index = edge_index\n",
        "        pyg_graph.num_nodes = num_nodes\n",
        "        sample_graphs.append(pyg_graph)\n",
        "\n",
        "        # print(edge_index)\n",
        "    return sample_graphs\n",
        "\n",
        "def prepare_dataset_x(dataset):\n",
        "    if dataset[0].x is None:\n",
        "        max_degree = 0\n",
        "        degs = []\n",
        "        for data in dataset:\n",
        "            degs += [degree(data.edge_index[0], dtype=torch.long)]\n",
        "            max_degree = max( max_degree, degs[-1].max().item() )\n",
        "            data.num_nodes = int( torch.max(data.edge_index) ) + 1\n",
        "\n",
        "        if max_degree < 2000:\n",
        "            # dataset.transform = T.OneHotDegree(max_degree)\n",
        "\n",
        "            for data in dataset:\n",
        "                degs = degree(data.edge_index[0], dtype=torch.long)\n",
        "                data.x = F.one_hot(degs, num_classes=max_degree+1).to(torch.float)\n",
        "        else:\n",
        "            deg = torch.cat(degs, dim=0).to(torch.float)\n",
        "            mean, std = deg.mean().item(), deg.std().item()\n",
        "            for data in dataset:\n",
        "                degs = degree(data.edge_index[0], dtype=torch.long)\n",
        "                data.x = ( (degs - mean) / std ).view( -1, 1 )\n",
        "    return dataset\n",
        "\n",
        "\n",
        "seed = 1314\n",
        "\n",
        "dataset = custom_dataset\n",
        "dataset = list(dataset)\n",
        "\n",
        "for graph in dataset:\n",
        "    graph.y = graph.y.view(-1)\n",
        "\n",
        "dataset = prepare_dataset_onehot_y(dataset)\n",
        "\n",
        "\n",
        "random.seed(seed)\n",
        "random.shuffle( dataset )\n",
        "\n",
        "train_nums = int(len(dataset) * 0.7)\n",
        "train_val_nums = int(len(dataset) * 0.8)\n",
        "\n",
        "avg_num_nodes, avg_num_edges, avg_density, median_num_nodes, median_num_edges, median_density = stat_graph(dataset[: train_nums])\n",
        "logger.info(f\"avg num nodes of training graphs: { avg_num_nodes }\")\n",
        "logger.info(f\"avg num edges of training graphs: { avg_num_edges }\")\n",
        "logger.info(f\"avg density of training graphs: { avg_density }\")\n",
        "logger.info(f\"median num nodes of training graphs: { median_num_nodes }\")\n",
        "logger.info(f\"median num edges of training graphs: { median_num_edges }\")\n",
        "logger.info(f\"median density of training graphs: { median_density }\")\n",
        "\n",
        "resolution = int(median_num_nodes)\n",
        "\n",
        "class_graphs = split_class_graphs(dataset[:train_nums])\n",
        "graphons = []\n",
        "ge = 'USVT'\n",
        "for label, graphs in class_graphs:\n",
        "\n",
        "        logger.info(f\"label: {label}, num_graphs:{len(graphs)}\" )\n",
        "        align_graphs_list, normalized_node_degrees, max_num, min_num = align_graphs(\n",
        "            graphs, padding=True, N=resolution)\n",
        "        logger.info(f\"aligned graph {align_graphs_list[0].shape}\" )\n",
        "\n",
        "        logger.info(f\"ge: {ge}\")\n",
        "        graphon = universal_svd(align_graphs_list, threshold=0.2)\n",
        "        graphons.append((label, graphon))\n",
        "\n",
        "\n",
        "for label, graphon in graphons:\n",
        "    logger.info(f\"graphon info: label:{label}; mean: {graphon.mean()}, shape, {graphon.shape}\")\n",
        "\n",
        "aug_ratio = 0.15\n",
        "aug_num = 10\n",
        "lam_range = [0.005, 0.01]\n",
        "\n",
        "\n",
        "num_sample = int( train_nums * aug_ratio / aug_num )\n",
        "lam_list = np.random.uniform(low=lam_range[0], high=lam_range[1], size=(aug_num,))\n",
        "\n",
        "random.seed(seed)\n",
        "new_graph = []\n",
        "for lam in lam_list:\n",
        "    logger.info( f\"lam: {lam}\" )\n",
        "    logger.info(f\"num_sample: {num_sample}\")\n",
        "    two_graphons = random.sample(graphons, 2)\n",
        "    new_graph += two_graphons_mixup(two_graphons, la=lam, num_sample=num_sample)\n",
        "    logger.info(f\"label: {new_graph[-1].y}\")\n",
        "\n",
        "avg_num_nodes, avg_num_edges, avg_density, median_num_nodes, median_num_edges, median_density = stat_graph(new_graph)\n",
        "logger.info(f\"avg num nodes of new graphs: { avg_num_nodes }\")\n",
        "logger.info(f\"avg num edges of new graphs: { avg_num_edges }\")\n",
        "logger.info(f\"avg density of new graphs: { avg_density }\")\n",
        "logger.info(f\"median num nodes of new graphs: { median_num_nodes }\")\n",
        "logger.info(f\"median num edges of new graphs: { median_num_edges }\")\n",
        "logger.info(f\"median density of new graphs: { median_density }\")\n",
        "\n",
        "dataset = new_graph + dataset\n",
        "logger.info( f\"real aug ratio: {len( new_graph ) / train_nums }\" )\n",
        "train_nums = train_nums + len( new_graph )\n",
        "train_val_nums = train_val_nums + len( new_graph )\n",
        "\n",
        "dataset = prepare_dataset_x( dataset )\n",
        "\n",
        "logger.info(f\"num_features: {dataset[0].x.shape}\" )\n",
        "logger.info(f\"num_classes: {dataset[0].y.shape}\"  )"
      ],
      "metadata": {
        "id": "eJyDOya-0LhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XLzdqO2kfZz",
        "outputId": "454ac5c5-4191-405c-969b-8c589a82731e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45437\n"
          ]
        }
      ]
    }
  ]
}